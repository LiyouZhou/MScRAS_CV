\documentclass{report}
\usepackage{graphicx} % Required for inserting images
\usepackage{biblatex} %Imports biblatex package
\usepackage{hyperref} % Required for adding links and customizing them
\usepackage[toc,page]{appendix}
\usepackage{subcaption}
\usepackage{listings}
\lstset{
  breaklines=true,
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
}
\usepackage{array}
\usepackage{amsmath}
\usepackage{placeins}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{cleveref}

% color def
\usepackage{color}
\definecolor{darkred}{rgb}{0.6,0.0,0.0}
\definecolor{darkgreen}{rgb}{0,0.50,0}
\definecolor{lightblue}{rgb}{0.0,0.42,0.91}
\definecolor{orange}{rgb}{0.99,0.48,0.13}
\definecolor{grass}{rgb}{0.18,0.80,0.18}
\definecolor{pink}{rgb}{0.97,0.15,0.45}

% listings
\usepackage{listings}

% General Setting of listings
\lstset{
  aboveskip=1em,
  breaklines=true,
  abovecaptionskip=-6pt,
  captionpos=b,
  escapeinside={\%*}{*)},
  frame=single,
  numbers=left,
  numbersep=15pt,
  numberstyle=\tiny,
}
% 0. Basic Color Theme
\lstdefinestyle{colored}{ %
  basicstyle=\ttfamily,
  backgroundcolor=\color{white},
  commentstyle=\color{green}\itshape,
  keywordstyle=\color{blue}\bfseries\itshape,
  stringstyle=\color{red},
}
% 1. General Python Keywords List
\lstdefinelanguage{PythonPlus}[]{Python}{
  morekeywords=[1]{,as,assert,nonlocal,with,yield,self,True,False,None,} % Python builtin
  morekeywords=[2]{,__init__,__add__,__mul__,__div__,__sub__,__call__,__getitem__,__setitem__,__eq__,__ne__,__nonzero__,__rmul__,__radd__,__repr__,__str__,__get__,__truediv__,__pow__,__name__,__future__,__all__,}, % magic methods
  morekeywords=[3]{,object,type,isinstance,copy,deepcopy,zip,enumerate,reversed,list,set,len,dict,tuple,range,xrange,append,execfile,real,imag,reduce,str,repr,}, % common functions
  morekeywords=[4]{,Exception,NameError,IndexError,SyntaxError,TypeError,ValueError,OverflowError,ZeroDivisionError,}, % errors
  morekeywords=[5]{,ode,fsolve,sqrt,exp,sin,cos,arctan,arctan2,arccos,pi, array,norm,solve,dot,arange,isscalar,max,sum,flatten,shape,reshape,find,any,all,abs,plot,linspace,legend,quad,polyval,polyfit,hstack,concatenate,vstack,column_stack,empty,zeros,ones,rand,vander,grid,pcolor,eig,eigs,eigvals,svd,qr,tan,det,logspace,roll,min,mean,cumsum,cumprod,diff,vectorize,lstsq,cla,eye,xlabel,ylabel,squeeze,}, % numpy / math
}
% 2. New Language based on Python
\lstdefinelanguage{PyBrIM}[]{PythonPlus}{
  emph={d,E,a,Fc28,Fy,Fu,D,des,supplier,Material,Rectangle,PyElmt},
}
% 3. Extended theme
\lstdefinestyle{colorEX}{
  basicstyle=\ttfamily,
  backgroundcolor=\color{white},
  commentstyle=\color{darkgreen}\slshape,
  keywordstyle=\color{blue}\bfseries\itshape,
  keywordstyle=[2]\color{blue}\bfseries,
  keywordstyle=[3]\color{grass},
  keywordstyle=[4]\color{red},
  keywordstyle=[5]\color{orange},
  stringstyle=\color{darkred},
  emphstyle=\color{pink}\underbar,
}

\lstset{style=colorEX}

\newenvironment{conditions}
  {\par\vspace{\abovedisplayskip}\noindent\begin{tabular}{>{$}l<{$} @{${}={}$} l}}
  {\end{tabular}\par\vspace{\belowdisplayskip}}

\setlength{\abovecaptionskip}{5pt}

\graphicspath{{./figures/}}
\addbibresource{CV.bib} %Import the bibliography file

\title{Computer Vision Coursework Report}
\author{Liyou Zhou}

\begin{document}
\maketitle


\chapter{Task 1: Image Segmentation and Detection}

\section{Segmentation Pipeline}

The code for the pipeline task is shown in Appendix~\ref{sec:app_task1}.

\subsection{Color Mask}

The tennis ball is of a bright yellow color, which is unique in the image. Therefore, this information can be used to segment the tennis ball. The image is first transformed into HSV space. The color is expressed solely by the hue channel, tight threshold can be applied on the hue channel but allow variation in the saturation and value to achieve lighting invariance.

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{yellow_ball_mask_seq.png}
    \caption{Color mask applied to several frames.}
    \label{fig:color_mask}
\end{wrapfigure}

After thresholding, there are still some noise. Opening and closing are applied to remove the noise and fill the gaps. Finally, a connected component analysis is applied and only the largest connected component is returned as the mask.

Fig. \ref{fig:color_mask} shows the result of the color mask over several frames. It can be seen that it segments the tennis ball very well.



\subsection{Edge Mask}

The edge mask is obtained by first applying the Canny edge detector\cite{cannyComputationalApproachEdge1986} to the image. The edge detected is shown in Fig. \ref{fig:edge_mask}.

Many iterations of closing are applied to close the gaps and many iterations of opening is used to remove noise. The result is shown in Fig. \ref{fig:morph_mask}.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{edge_detection.png}
        \caption{Canny edge detector on one frames}
        \label{fig:edge_mask}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{morph_mask.png}
        \caption{Edge mask after closing and opening}
        \label{fig:morph_mask}
    \end{subfigure}
    \caption{Edge Mask}
    \label{fig:edge_masks}
\end{figure}

\begin{wrapfigure}{r}{.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{motion_mask.png}
    \caption{Motion mask applied to one of the frames}
    \label{fig:motion_mask}
\end{wrapfigure}

It can be seen the balls are well masked. But there is also large areas of false positives on the top half of the image. In the next section, a region of interest is devised to remove most of the false positive pixels.

\subsection{Motion Mask}

In the dataset images, only the balls are moving across the image while the rest of the image stay still. I use the difference of pixels in adjacent images to detect a region of interest just around the balls. The result is shown in Fig. \ref{fig:motion_mask}. I first calculate the absolute difference of pixel values in adjacent frames, then I use opening and closing to de-noise and fill gaps. The resultant mask is then dilated to allow for better coverage of the balls.

\subsection{Combining Masks}

The color mask and edge masked are ``OR"ed together, then ``AND"ed with the motion mask to produce the final mask. Some example segmented frames can be seen in Fig~\ref{fig:best_dice_score_1} and Appendix~\ref{sec:app_task1}.

\begin{wrapfigure}{r}{.5\textwidth}
    \centering
    \includegraphics[width=.5\textwidth]{best_dice_score_1.png}
    \caption{Best dice score frame. Green circle indicates the ground truth segmentation mask.}
    \label{fig:best_dice_score_1}
\end{wrapfigure}

\section{Evaluation and Discussion}

Dice score is calculated to evaluate the segmentation. The mean dice score is 0.850 and standard deviation of 0.0891. Fig. \ref{fig:dice_score} shows the score for each frame and Fig. \ref{fig:dice_score_hist} shows the distribution of the scores.

Appendix~\ref{sec:app_task1} show the 5 best and 5 worst frames. Looking at the worst frames, it looks like spurious patches that are not balls started to appear in the motion mask, reducing the dice score. The color of the rugby ball blends into that of the floor making the edge detection fail, further reducing the dice score.

\begin{figure}
    \centering
    \includegraphics[width=0.7\columnwidth]{dice_score.png}
    \caption{Dice score for each frame}
    \label{fig:dice_score}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.7\columnwidth]{dice_score_hist.png}
    \caption{Histogram of dice scores}
    \label{fig:dice_score_hist}
\end{figure}

\chapter*{Task 2: Feature Calculation}

The code to solve this task is shown in Appendix~\ref{sec:app_task_2}.

\section{Separating ball masks}

In order to distinguish between ball types, it is necessary to separate the single ground truth segmentation mask into 3 different masks, one for each ball type.

The following properties of the balls are exploited:

\begin{itemize}
    \item Tennis is always the smallest in the image.
    \item Rugby is always the bottom most of the 3 balls.
    \item Football is the one left after removing the other 2 balls.
\end{itemize}

\section{Shape Features}

After obtaining the ground truth shape mask for each individual ball types, shape features (solidity, non-compactness\cite{westenbergVolumetricAttributeFiltering2007,bosiljConnectedAttributeMorphology2018}, circularity\cite{zunicHuMomentInvariant2010}, eccentricity) are calculated for each ball type and histogram of the feature values is plotted for each ball type in Fig.~\ref{fig:shape_features_hist}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\columnwidth]{shape_features_hist.png}
    \caption{Histogram different shape features}
    \label{fig:shape_features_hist}
\end{figure}

\section{Texture Features}

The normalized grey-level co-occurrence matrix in four orientations (0째, 45째, 90째, 135째) are calculated for the three ball types and for each r, g, b channels of the images. 3 texture features are then calculated for each of the co-occurrence matrices. The mean and range of the features across the 4 angles is calculated. A histogram is plotted for the mean and range of the features in each color channels. ASM features are produced in Fig~\cref{fig:r_ASM,fig:g_ASM,fig:b_ASM} as it shows the most disparity between ball types. Plots for other color feature pairs are produced in Appendix~\ref{sec:app_task_2}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{r_ASM.png}
    \caption{ASM feature in the R channel}
    \label{fig:r_ASM}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{g_ASM.png}
    \caption{ASM feature in the G channel}
    \label{fig:g_ASM}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{b_ASM.png}
    \caption{ASM feature in the B channel}
    \label{fig:b_ASM}
\end{figure}

\section{Discussion}

In shape features, the rugby ball is fairly distinct from the other 2, especially in circularity (low), eccentricity (high). But due to the change in lens distortion and perspective as the balls roll across the frame, there is a wide spread in the shape features for all ball types.

In texture features, ASM is the most distinct feature between the ball types and in all color channels. In the R channel, The rugby ball has the lowest ASM, while the tennis ball has the highest. This is due to the tennis ball having an almost uniform texture compared to the other 2 balls. Due to the same reason, the rugby ball also has the highest contrast and correlation values. In the G and B channel, due to the color of the rugby being mostly in the R channels, the values for the features are wide-spread.

For rugby, shape features appear to be more informative while for the other 2 ball types texture features are better.

Football is the most difficult to distinguish as it is of a bright color and uniform texture, and is hence similar to the tennis in most of the descriptors. Rugby on the other hand is distinct in shape as well as in color.

The Hue values of the ball patches in HSV color space could be a good feature to use in distinguishing between football and tennis as they differ significantly in the hue.

\chapter{Task 3: Object Tracking}

Based on example shown in workshop 4, a Kalman filter\cite{kalmanNewApproachLinear1960} is implemented in python. The code is shown in Appendix~\ref{sec:app_task3}.

With the Q and R values provided in the task, the Kalman filter is applied to the noisy observations. Fig.~\ref{fig:kalman_filter_default_values} plots the filtered trajectory alongside the ground truth and the original observations. When compared to the ground truth, the root mean squared error (RMSE) is calculated according to Eq.~\ref{eq:rmse} to be is 5.87. The squared error is calculated for each ground truth point and the distribution is shown in Fig.~\ref{fig:kalman_filter_error_hist}. The standard deviation of the squared error is 24.7.

\begin{equation}
    RMSE = \sqrt{\frac{1}{N} \sum_{i=1}^{N} ((x_{i} - \hat{x}_{i})^2 + (y_{i} - \hat{y}_{i})^2)}
    \label{eq:rmse}
\end{equation}
Where:
\begin{conditions}
 x_{i},\ y_{i}             & the ground truth coordinate values \\
 \hat{x}_{i},\ \hat{y}_{i} & the filtered coordinate values \\
 N                         & the number of points
\end{conditions}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{kalman_filter_default_values.png}
    \caption{Kalman filter applied to the noisy observations with default Q and R values.}
    \label{fig:kalman_filter_default_values}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{kalman_filter_error_hist.png}
    \caption{Kalman filter applied to the noisy observations with default Q and R values, Histogram of squared error (difference between filtered value and ground truth) when compared to ground truth.}
    \label{fig:kalman_filter_error_hist}
\end{figure}


It can be seen the filtered trajectory track very close to the Noisy observations. 
Observation error (difference between ground truth and observations) is calculated at each time step and the distribution is shown in Fig.~\ref{fig:observation_error_hist}. The standard deviation for both x and y is just above 5 and the mean is -1.1 for the x error and -0.61 for the y error. In the Kalman filter, the error is modelled a Gaussian noise with mean 0 and covariance R. Increasing the R will decrease the confidence in the observations and the filtered trajectory will be dragged less towards the observations at each iteration. If we set R relatively large:

\[R = \begin{bmatrix} 
    10 & 0 \\
    0 & 10 \\
\end{bmatrix}\]

and re-plot the above graph (Fig.~\ref{fig:kalman_filter_larger_obs_noise}), it can be seen that filtered value react more slowly to new observations and tend more to follow the motion model. This, however, did not reduce the RMSE, which is now 16.4. There need to be a balance between following the process and following the observations. There is also evidence that the observation noise should not be the same in the x and y direction. The errors in x tends to be larger.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{observation_error_hist.png}
    \caption{Histogram of observation error (difference between observation and ground truth) in x and y}
    \label{fig:observation_error_hist}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{kalman_filter_larger_obs_noise.png}
    \caption{Kalman filter applied to the noisy observations with \(R = \begin{bmatrix} 
        10 & 0 \\
        0 & 10 \\
    \end{bmatrix}\)}
    \label{fig:kalman_filter_larger_obs_noise}
\end{figure}

Acceleration is calculated for the ground truth data and the histogram is shown in Fig.~\ref{fig:acceleration_hist}. Acceleration sits between -17 and 17. In the Kalman filter the motion model used assumes constant velocity. As each time step is \(dt=0.5s\), if the acceleration is \(a = 17 m/s^2\), the velocity will change by \(a \times dt = 8.5m/s\). This acceleration is only accounted for by the process noise Q. If the acceleration is higher than the process noise, the filter will not be able to track the object accurately. There is also strong evidence that the process noise should not be the same in the x and y direction as the acceleration tends to be higher in the y direction.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{acceleration_hist.png}
    \caption{Histogram of accelerations in x and y in the ground truth}
    \label{fig:acceleration_hist}
\end{figure}

Keeping the assumption that the noise in x and y are independent of each other, i.e. keeping Q and R diagonal, an optimization algorithm is used to tune the diagonal values to achieve the lowest RMSE. The final Q and R values are:

\begin{equation}
R = \begin{bmatrix} 
    0.29 & 0    \\
    0    & 0.89 \\
\end{bmatrix}\ and\ Q = \begin{bmatrix} 
    0 & 0    & 0    & 0    \\
    0 & 0.56 & 0    & 0    \\
    0 & 0    & 0.15 & 0    \\
    0 & 0    & 0    & 0.02 \\
\end{bmatrix}
\end{equation}

The RMSE is 5.24 which is 10.7\% lower than when using the default values. The filtered trajectory is shown in Fig.~\ref{fig:kalman_filter_optimized}. It can be seen that it achieve a balance between following the observations and the process model.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{kalman_filter_optimized.png}
    \caption{Kalman filter applied to the noisy observations with optimized Q and R values.}
    \label{fig:kalman_filter_optimized}
\end{figure}

Ultimately, the Kalman filter is a linear model and is not able to account for the non-linear motion of the balls. If Extended Kalman filter\cite{julierNewExtensionKalman1997} or Unscented Kalman filter\cite{wanUnscentedKalmanFilter2000} is implemented, a non-linear process model  such as constant acceleration model can be used, the RMSE may be further reduced.

\printbibliography

\begin{appendices}

\chapter{Task 1: Image Segmentation and Detection}\label{sec:app_task1}

\section{5 Best and 5 Worst Dice Score Frames}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_1.png}
    \caption{Best dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_2.png}
    \caption{2nd best dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_3.png}
    \caption{3rd best dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_4.png}
    \caption{4th best dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_5.png}
    \caption{5th best dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_63.png}
    \caption{Worst dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_62.png}
    \caption{2nd worst dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_61.png}
    \caption{3rd worst dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_60.png}
    \caption{4th worst dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{best_dice_score_59.png}
    \caption{5th worst dice score frame. Green circle indicates the ground truth segmentation mask.}
\end{figure}

\pagebreak

\section{Code Listing for Task 1}

\lstinputlisting[language=PyBrIM]{../code/task1.py}

\chapter{Task 2: Feature Calculation}\label{sec:app_task_2}

\section{Extra Texture Feature/Color Channel Plots}

\begin{figure}
    \includegraphics[width=0.8\columnwidth]{r_contrast.png}
\end{figure}

\begin{figure}
    \includegraphics[width=0.8\columnwidth]{r_correlation.png}
\end{figure}

\begin{figure}
    \includegraphics[width=0.8\columnwidth]{g_contrast.png}
\end{figure}

\begin{figure}
    \includegraphics[width=0.8\columnwidth]{g_correlation.png}
\end{figure}

\begin{figure}
    \includegraphics[width=0.8\columnwidth]{b_contrast.png}
\end{figure}

\begin{figure}
    \includegraphics[width=0.8\columnwidth]{b_correlation.png}
\end{figure}

\pagebreak

\section{Code Listing for Task 2}


\lstinputlisting[language=PyBrIM]{../code/task2.py}

\chapter{Task 3: Object Tracking} \label{sec:app_task3}

\section{Code Listing for Task 3}

\lstinputlisting[language=PyBrIM]{../code/task3.py}

\end{appendices}

\end{document}
